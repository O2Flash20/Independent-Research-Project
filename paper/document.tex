\documentclass[english,12pt,a4paper,final]{article}
\usepackage[T1]{fontenc}
\usepackage{babel}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{relsize}
\usepackage[normalem]{ulem}
\usepackage{xcolor}
\usepackage{parskip}
\usepackage{hyperref}
\usepackage{float}
\usepackage[a4paper, total={6.27in, 9.69in}]{geometry}

\definecolor{OliveGreen}{rgb}{0,0.6,0}
\definecolor{firebrick}{rgb}{0.7, 0.13, 0.13}

\usepackage[backend=biber, style=authoryear]{biblatex}
\addbibresource{bibliography.bib}
\DeclareDelimFormat{nameyeardelim}{\addcomma\space}

\hypersetup{
	colorlinks=true,
	linkcolor=black,
	urlcolor=blue,
	citecolor=firebrick,
	pdftitle={Exploring Variations of Penney's Game},
	pdfauthor={William Dracopoulos}
}

\title{Exploring Variations of Penney's Game}
\author{
William Dracopoulos \& Derrick Chung
\\
John Abbott College
}

\begin{document}
	
\maketitle
\newpage

\tableofcontents
\newpage

\part{Abstract}

Penney’s Game is an example of where our intuitive understanding of probability completely fails; it’s a seemingly fair game with a surprisingly complicated strategy. The goal of this research is to explore Penney’s Game using new methods and in areas that it has not been explored before. By studying a similar game that is fair, we create a formula for the probability of each player winning Penney’s Game depending on the number of players, the sequences chosen by each player, the length of each sequence, the number of possible outcomes of the “flip” (coin flip or dice roll or random outcome generation), and the probability distribution of the outcomes of this flip. This formula was verified by computer simulations and then packaged into an online calculator. The calculator then revealed patterns which were analyzed using the formula. Among these, it was proven that games tend towards being fair with an infinite number of possible outcomes from the “flip” but not infinite sequence length, and that the shorter sequence always has an advantage, except in some specific and known cases. The work done in this paper is not exhaustive, there is still plenty to explore and discover, and we leave behind tools to help future researchers to do this.

\part{Introduction}

In its basic variation, Penney's Game is simple game invented by Walter Penney involving two players and one coin. Each player predicts which sequence of flips will appear first as the coin is being flipped. For example, Alice predicts that HHT (heads, then heads, then tails) will appear first, while Bob predicts that THT (tails, then heads, then tails) will appear first. The players flip the coin until the last three coin flips match with the sequence predicted by one of the players. That player wins. Note that this does not mean the coin is flipped three times, a match is checked for, and then it's flipped three times again. Instead, after every coin flip, the last three flips are checked to see if they match with a player's prediction.

The game might seem fair, but it really is not. In that example, Alice actually has a 62.5\% chance of beating Bob. In fact, for any sequence that one player predicts, there is another that will, beat it on average \parencite{penney}. A formula for finding the exact win probabilities for any sequence in this basic variation of the game was first discovered by the mathematician John Conway, but he never supplied a proof of his "leading number algorithm".

Since Conway, many other researchers have developed other algorithms and ways of thinking about the problem. One way is using Markov chains and martingale arguments, such as the paper by \textcite{markov}'s. However, we hope to use a much simpler way of understanding the game and deriving a formula for win probabilities. The general idea, which will be explained in depth during the next part, is to think about another game instead, which this time is always fair. This new game, which we will call the betting game, contains the same probabilities as Penney's Game but allows for a clear and powerful starting point due to its fairness. The idea of the betting game comes simultaneously from two places: a research paper which tackles Penney's game from the perspective of no-arbitrage \parencite{miller}, and \textcite{chung}'s talk which mentions describes it in the context of the Optional Stopping Theorem. The latter will be the same approach used in this paper. Our goal is to extend the betting game analogy further than ever before to allow us to determine probabilities in many variations of Penney's Game.

A formula, \eqref{generalFormula}, will be derived which can calculate the win probabilities in games with:

\begin{enumerate}
	\item Any number of players
	\item Players predicting more or less than the next three flips, and  players predicting a different number of flips to each other
	\item Any kind of coin, die, or random outcome generator being "flipped"
	\item Unfair coins, loaded dice, and random outcome generators with any probability distribution
\end{enumerate}

We also hope to verify our formula with simulations, and then analyze it to discover new things about Penney's Game in some of the variations covered by the formula.

\part{Showing that Penney's Game is unintuitive, and providing some hope that it can be understood}

The game was introduced as seeming fair but actually being biased. However, sometimes it seems like one player should be advantaged, while in reality the game is completely fair.

Imagine sitting at a table and flipping a coin until there are three consecutive heads. You should find that, on average, HHH appears after the 14th coin flip. Now you do the same and count how many flips it takes to get HHT. This time, you count that HHT appears after only the 8th coin flip on average. We went through this process and collected data for each sequence in the basic variation, which is shown in Figure \ref{fig:probGraph}.

\newpage

\begin{figure}
	\centering
	\includegraphics[width=0.7\linewidth]{"./prob graph"}
	\caption{Probability of a sequence appearing for the first time as a function of the number of coin flips. The data was obtained from a simulation of 1 000 000 repetitions. The expected wait time (number of flips until the sequence appears) for the purple, black, and green lines are calculated to be approximately 8 flips, 10 flips, and 14 flips respectively.}
	\label{fig:probGraph}
\end{figure}

An exact function for the green line was found by my friend Fenghua Li to be 
\begin{equation*}
	\mathbb{P}_n=\frac{1}{16} A(n-4)
\end{equation*}
\begin{equation*}
	A(m) = \frac{1}{2^m}\sum_{s=0}^{m- \lfloor \frac{m}{3} \rfloor}\sum_{L=\lceil \frac{s}{2} \rceil}^{s} {m+1-s \choose L} {L \choose s-L}
\end{equation*}
This gives the probability of the sequence appearing, $\mathbb{P}$, for any number of previous coin flips $n$.

This might lead you to believe that HHT would beat HHH in Penney's Game, since it would appear earlier, but in fact HHT vs. HHH would be a fair game. Figure \ref{fig:probGraph} does not show the whole picture. It does not take into account how the sequences interact with each other. The difference is that the expected wait time comes from one player flipping one coin, but in Penney's Game it's two players checking for their sequence on the same coin. Imagine the last two coin flips were heads. There is now a 50:50 chance that the third flip will land on heads and tails. Therefore it is equally likely that HHT and HHH appears, so the game is fair.

The situation is very different if you switch it around to be THH vs. HHH however. This will actually give the greatest probability difference in the basic variation of the game: the player predicting HHH will only have a 12.5\% (or $\frac{1}{8}$) chance of winning. This is because as soon as a single coin flip lands on tails, HHH has no chance of appearing before THH: THH will always get to two heads in a row before HHH gets to three in a row. This leaves only one way for HHH to win: if the first three coin flips land on heads, which is a $\frac{1}{2^3} = \frac{1}{8}$ chance.

We have shown that Penney's Game is unintuitive but not completely impossible to understand. Now we can move on to analyzing it through the betting game to develop a general formula for win probabilities.

\part{Deriving a formula for win probabilities with two players}

\section{The basic variation of Penney's Game}

Imagine two players sitting at a table with one coin between them. Each player picks a sequence and they begin to flip the coin until the last flips match with one of the player's sequences. Up until now, the game has been identical to Penney's Game, and that is by design. Now it begins to differ. This is how the betting game works:

Right before each coin flip, both players bet on their chosen sequence appearing in the next flips. Note that this means each player will likely have multiple bets going on at the same time, since a new sequence of bets starts for each flip, and each bet might last multiple flips. The players are betting against each other: if one wins \$2, it's the other player that gives it to them. Although the game ends when one player's sequence appears in the flips, it does not necessarily mean that the player wins. There is no winner nor loser, just an exchange of money.
\\\\
We will explain using an example: Let's say Alice chooses HHT and Bob chooses THT. We'll start by following the sequence of bets that starts from the first flip. Before the coin is flipped for the first time, Alice bets that the flips will follow her sequence, so she bets that the first will be H, the second H, and the third T. Bob simultaneously bets that the first flip will be T, the second H, and the third T. Both players start by betting \$1 on this. If they win, they will have \$2 and they will use that to bet on the second flip, and so on, doubling each time. If they lose, that \$1 is gone. By random chance, the coin lands on heads. Alice now has \$2 and Bob has lost the bet: his prediction has failed and he lost the \$1 to Alice. He also has to pay \$1 to Alice for her win. So she actually has \$3 and he has -\$1. But Alice continues, she bets the \$2 from her win on the next flip being heads. They flip the coin again and it lands on heads. Alice  now has \$5 after winning another \$2 from Bob, and Bob has -\$3. She bets the \$4 from her correct bets so far on tails to finish her sequence of HHT. The third flip lands on heads instead. Alice loses that \$4 to Bob, so they start back where they began: each has \$1.

So this whole thing was useless, and there can be any number of useless sequences of bets like this until the game ends. But remember that each time a coin was flipped, each player starts new bets on their chosen sequence of flips.

This game actually ends one flip later, with Alice's sequence appearing in the coin flips. We will illustrate this game in a table. The top row represents the coin flips that actually occur. All other rows represent a new sequence of bets that the player makes. Notice that the row labelled 1 shows the sequence of bets that we described above: the sequence that starts at the first coin flip. But there were three more sequences of bets until the game ended.

To simplify, we can think of the bets slightly differently. We can ignore the constant exchange of money between players, and have them only give each other money when the game ends.
\\\\\\
Alice:
\begin{tabular}{|c|c|c|c|c|}
	\hline
	& H & H & H & T \\
	\hline
	1 & \textcolor{OliveGreen}{H} & \textcolor{OliveGreen}{H} & \textcolor{red}{\sout{T}} &  \\
	\hline
	2 &  & \textcolor{OliveGreen}{H} & \textcolor{OliveGreen}{H} & \textcolor{OliveGreen}{T} \\
	\hline
	3 &  &  & \textcolor{OliveGreen}{H} & \textcolor{red}{\sout{H}} \\
	\hline
	4 &  &  &  & \textcolor{red}{\sout{H}} \\
	\hline
\end{tabular}
\\\\\\
We colour the successful bets in green and the unsuccessful ones in red. Alice has a single sequence of bets that was successful: row 2. From it, she is at \$8 because her three bets in a row were successful, also meaning that Alice made the game end. From the other sequences, she has nothing. So we can say that Alice has \$8 and therefore Bob owes her \$8. But during this time, what was Bob doing?
\\\\\\
Bob:
\begin{tabular}{|c|c|c|c|c|}
	\hline
	& H & H & H & T \\
	\hline
	1 & \textcolor{red}{\sout{T}} & H & T &  \\
	\hline
	2 &  & \textcolor{red}{\sout{T}} & H & T \\
	\hline
	3 &  &  & \textcolor{red}{\sout{T}} & H \\
	\hline
	4 &  &  &  & \textcolor{OliveGreen}{T} \\
	\hline
\end{tabular}
\\\\\\
In all rows except 4, Bob loses the sequence of bets on the first one. So all others after it are not coloured, indicating that they don't have an opportunity to happen at all. He won the first bet in row 4, but his bets were cut off from Alice winning the game, meaning that Bob gets to keep the \$2 he won from it.

In total, Bob owes Alice \$8, but Alice owes Bob \$2. After the exchange, Alice has \$6 and Bob has -\$6.

If either player had received money from another sequence of bets which started at another flip, it would get added to the total.

It is very important to notice that the final share of money is not unique to this game in particular. In any game where Alice's sequence of HHT appears before Bob's sequence of THT, Alice will end up getting \$6 from Bob. This is because all of the flips before the last three do not matter: the prior bets of both Alice and Bob will fail eventually. The only two ways for a player to make money from a sequence of bets are:

\begin{enumerate}
	\item If the bets go to completion. In other words, if the three bets in a row succeed. This will end the game.
	\item If a sequence of bets gets cut off by the game ending.
\end{enumerate}

We can ignore all sequences of bets before the last three because we know they won't give anyone any money. They can't return money in the first way because then the game would be over already. And we cover all bets that might return money in the second way by including the last two sequences of bets.

We can now introduce a better version of the table, which we will use throughout the paper.
\\\\\\
$R_A(A)$:
\begin{tabular}{|ccc|c|}
	\hline
	H & H & T & Gain \\
	\hline
	
	\textcolor{OliveGreen}{H} & \textcolor{OliveGreen}{H} & \textcolor{OliveGreen}{T} & $2^3=8$ \\
	
	& \textcolor{OliveGreen}{H} & \textcolor{red}{\sout{H}} & $0$ \\
	
	&  & \textcolor{red}{\sout{H}} & $0$ \\
	\hline
\end{tabular}
$=8$
\\\\\\
It now only features the important rows: the last 3. And it shows that Alice's (denoted by the $A$ within the parentheses) "return" ($R$) when her own sequence (denoted by the $A$ in the subscript) appears as the coin is flipped will be \$8.

The same table can be made for Bob's return when Alice's sequence appears:
\\\\\\
$R_A(B)$:
\begin{tabular}{|ccc|c|}
	\hline
	H & H & T & Gain \\
	\hline
	
	\textcolor{red}{\sout{T}} & H & T & $0$ \\
	
	& \textcolor{red}{\sout{T}} & H & $0$ \\
	
	&  & \textcolor{OliveGreen}{T} & $2$ \\
	\hline
\end{tabular}
$=2$
\\\\\\\\\\
We have studied sufficiently what happens when Alice's sequence appears. Now let's focus on when Bob's sequence appears by making the tables:
\\\\\\
$R_B(A)$:
\begin{tabular}{|ccc|c|}
	\hline
	T & H & T & Gain \\
	\hline
	
	\textcolor{red}{\sout{H}} & H & T & $0$ \\
	
	& \textcolor{OliveGreen}{H} & \textcolor{red}{\sout{H}} & $0$ \\
	
	&  & \textcolor{red}{\sout{H}} & $0$ \\
	\hline
\end{tabular}
$=0$
\\\\\\
So Alice makes \$0 from Bob when his sequence appears in the coin flips.
\\\\\\\\

$R_B(B)$:
\begin{tabular}{|ccc|c|}
	\hline
	T & H & T & Gain \\
	\hline
	
	\textcolor{OliveGreen}{T} & \textcolor{OliveGreen}{H} & \textcolor{OliveGreen}{T} & $8$ \\
	
	& \textcolor{red}{\sout{T}} & H & $0$ \\
	
	&  & \textcolor{OliveGreen}{T} & $2$ \\
	\hline
\end{tabular}
$=10$
\\\\\\
And Bob makes \$10 from Alice when his sequence appears in the coin flips.
\\\\
In total, when Bob's sequence appears, Alice gives him \$10.

Note that something interesting is happening here. When Alice's sequence appears, Alice makes \$6 from Bob, but when Bob's sequence appears, he makes \$10 from Alice. This might make it seem like Bob has an advantage in this game, but there's a problem with that.
\\\\
\underline{Here is the point of all this:} All Alice and Bob are doing is betting on a fair coin, and either doubling or losing the money they put in. Each individual bet is \underline{fair}. But because of the linearity of expectation, it doesn't matter if you make a fair bet once or 100 times, on average, you should expect to neither lose nor gain money. Your expected profit should be 0.

But it seems like Bob is doing better than Alice, and that doesn't make sense \textit{assuming} that Bob's sequence and Alice's sequence have an equal chance of appearing. So let's simply assume that they don't. We'll take $\mathbb{P}(A)$ to mean the probability that Alice's sequence appears and ends the game, and $\mathbb{P}(B)$ to mean the probability that Bob's sequence appears and ends the game.

Let's look at it from Alice's perspective:

\begin{equation*}
	(\$6) \cdot \mathbb{P}(A)  + (-\$10) \cdot \mathbb{P}(B) = \$0
\end{equation*}

In words, Alice's net profit when her sequence appears (\$6) weighed by the chance that her sequence appears ($\mathbb{P}(A)$), added to Alice's net profit when Bob's sequence appears (-\$10) weighed by the chance that his sequence appears ($\mathbb{P}(B)$) is her expected profit, which for reasons explained above must be exactly \$0.

Now, of course, either Alice's or Bob's sequence must appear, so

\begin{equation}\label{PA+PB=1}
	\mathbb{P}(A) + \mathbb{P}(B) = 1
\end{equation}

We now have two equations and two unknowns, so $\mathbb{P}(A)$ and $\mathbb{P}(B)$ can be found. After some algebra, $\mathbb{P}(A) = 62.5\%$ and $\mathbb{P}(B) = 37.5\%$.

Importantly, this means that if Alice and Bob were playing Penney's Game with the sequences HHT and THT, Alice would have a 62.5\% chance of winning and Bob would have a 37.5\% chance of winning.

Generalizing beyond this example, we can define the net profit of Player X against Player Y when sequence Z appears (Z being either Player X or Player Y's sequence) as:

\begin{equation}\label{NtwoPlayers}
	N_Z(X) = R_Z(X) - R_Z(Y)
\end{equation}

Next, we can solve for $\mathbb{P}(A)$ and $\mathbb{P}(B)$ generally. From the perspective of Player A:

\begin{equation*}
	N_A(A)\cdot\mathbb{P}(A) + N_B(A)\cdot\mathbb{P}(B) = 0
\end{equation*}

Solving this with the help of \eqref{PA+PB=1}, we get

\begin{equation}\label{PtwoPlayersFirst}
	\mathbb{P}(A) = \frac{-N_B(A)}{N_A(A)-N_B(A)} = \frac{R_B(B)-R_B(A)}{R_A(A)-R_A(B)+R_B(B)-R_B(A)}
\end{equation}

And the formula for $\mathbb{P}(B)$ is exactly the same but with all A and B's swapped. This is exactly the same result as found by Miller and it is equivalent to Conway's leading number algorithm \parencite{miller}.

The last and most complicated thing to do is express the return values $R$ mathematically. The return in \$ for sequence $Y$ if the game ends by sequence $X$ appearing can be given by this equation, which simply describes the process done in the tables above:

\begin{equation}\label{Rbasic}
	R_X(Y) = \sum_{i=1}^{3} \prod_{j=1}^{i} 2_{[Y_j = X_{3-i+j}]}
\end{equation}

Where $2_{[Y_j = X_{3-i+j}]}$ is defined as:
\begin{equation*}
	2_{[Y_j = X_{3-i+j}]} = \begin{cases}
		2 & \text{if } Y_j = X_{3-i+j} \\
		0 & \text{if } Y_j \neq X_{3-i+j} \\
	\end{cases}
\end{equation*}

And the subscript of a sequence is its index. For example, in $X$: HTT, $X_1$ = H; $X_2$ = T; $X_3$ = T.

This equation is a specific case of Miller's formula for $R$.

\section{Allowing for any random outcome generator with any known probability distribution}

We have described Penney's Game as being played with a fair coin, but this is not necessary. We can extend the formula to account for any random outcome generator with any known probability distribution. For example, a random outcome generator can be a loaded 20-sided die or a coin flipped in a certain way so that it's more likely to land on heads\footnote{We provide a way to physically model loaded die and unfair coins in Part \ref{physicalModelling}.}. From now on, we will generalize all of these random outcome generators by imagining them as a random number generator that spits out integers $[0, 1, ..., n-1]$ for $n$ possible outcomes of the "flip". For example, instead of writing "heads" / "H" and "tails" / T" for a coin, we will write "0" and "1" because $n=2$. And a 6-sided die will be thought of as a generator outputting numbers $0, 1, 2, 3, 4, 5$.

To keep the betting game a valid analogy to Penney's Game, we need to keep the condition that the game must be fair, no matter which outcome generator is being used. This has a simple fix.

With a fair two-sided coin. We said that each bet is a double-or-nothing. This is because for a bet in which you put $\$X$, there is a 50\% chance of winning $\$X$ and a 50\% chance of losing $\$X$. Mathematically, the expected profit is 0, so

\begin{equation*}
	W \cdot \mathbb{P}(W) + L \cdot \mathbb{P}(L)=0
\end{equation*}

Meaning that the net profit from winning, $W$, weighted by the probability of winning, $\mathbb{P}(W)$, added to the net profit from losing, $L$, weighted by the probability of losing, $\mathbb{P}(L)$, should be zero.

Since this bet must either be won or lost, $\mathbb{P}(W) + \mathbb{P}(L) = 1$, so $\mathbb{P}(L) = 1-\mathbb{P}(W)$.

For example, in the case of a fair coin, 

\begin{equation*}
	X \cdot \frac{1}{2} + (-X) \cdot \frac{1}{2}=0
\end{equation*}

Now we can generalize for any $\mathbb{P}(W)$. We will say that the outcome of any bet will either be losing what you put into it, $L=-X$, or winning some multiple of what you put into it, $W=\lambda X$. We want to see which multiple $\lambda$ to use as a function of $\mathbb{P}(W)$.

\begin{equation*}
	(\lambda X) \cdot \mathbb{P}(W) + (-X) \cdot (1-\mathbb{P}(W)) = 0
\end{equation*}

\begin{equation*}
	\lambda = \frac{1}{\mathbb{P}(W)} - 1
\end{equation*}

In our table and our formula for $R$, we don't care about how much is won, but instead how much we're left with after a win. So after winning a bet of $X$, we will be left with a sum of $X'$ such that

\begin{equation*}
	\mathbf{X'} = X + \lambda X = X + \frac{X}{\mathbb{P}(W)} - X = \mathbf{X\frac{1}{\mathbb{P}(W)}}
\end{equation*}

So instead of a double or nothing, it must be a \textit{multiply your bet by $\frac{1}{\mathbb{P}(W)}$} or nothing. We can now include this new rule in our formula for $R$. Replacing the 2 in \eqref{Rbasic} by $\frac{1}{\mathbb{P}(W)}$, we get:

\begin{equation}\label{RanyRandom}
	R_X(Y) = \sum_{i=1}^{3} \prod_{j=1}^{i} \frac{1_{[Y_j = X_{3-i+j}]}}{\mathbb{P}(Y_j)}
\end{equation}

$\mathbb{P}(Y_j)$ is written instead of $\mathbb{P}(W)$ because, in this formula, the bet is being placed on the $j$th element of sequence $Y$ appearing, which we define to be $\mathbb{P}(Y_j)$. So $\mathbb{P}(Y_j)$ is the probability of winning. For example, with a fair coin, if sequence Y is HHT and $j=2$, then $\mathbb{P}(Y_j) = \mathbb{P}(H) = \frac{1}{2} = \mathbb{P}(W)$ and we return to what we had in \eqref{Rbasic} because $\frac{1}{(\frac{1}{2})} = 2$.

\section{Extending to games with sequences of different lengths}

As it was previously discussed, a sequence of bets can only return money (and therefore can only matter) if either of these things happen:
\begin{enumerate}
	\item The bets go to completion. In other words, if all bets in the sequence succeed. This will end the game.
	\item A sequence of bets gets cut off by the game ending.
\end{enumerate}

This allowed us to only look at the last 3 sequences of bets in the basic variation, because there will be 3 bets going on when the game ends, because the sequences predict the next three flips. For a game involving sequences of length $k$, all we have to change is that we should now look at the last $k$ sequences of bets before a player ends the betting. This is again a simple fix in the formula for $R$, introducing a $k$ in the place of the 3:

\begin{equation}\label{RanyLength}
	R_X(Y) = \sum_{i=1}^{k} \prod_{j=1}^{i} \frac{1_{[Y_j = X_{k-i+j}]}}{\mathbb{P}(Y_j)}
\end{equation}

At this point, our formula for $R$ is identical to the one derived by \textcite{miller}, despite some notation changes.

However, we can make one more small change to allow for games in which the players are predicting a different number of coin flips into the future compared to each other. For a sequence $S$, we will define its length (the number of flips predicted in the future) to be $L_S$.

Using the same logic as before, we find that the number of sequences of bets that must be checked when calculating $R_X(Y)$ must be $k = \text{min}\{L_X, L_Y\}$. Additionally, the subscript of X in $1_{[Y_j = X_{k-i+j}]}$ continues to involve the length of X, which has been changed from $k$ to $L_X$. This completes our work on $R$:

\begin{equation}\label{Rdef}
	R_{X}(Y) = \sum_{i=1}^{\text{min}\{L_{X}, L_{Y}\}} \prod_{j=1}^{i} \frac{1_{[Y_{j} = X_{L_{X} - i + j}]}}{\mathbb{P}(Y_{j})}
\end{equation}

It is important to note that having two or more sequences of different lengths leaves a lot of room for games which break the formula in some way. For example, 1100 vs. 100 would always be a tie in Penney's Game, since one sequence makes up the end of another. Additionally, 1100 vs. 110 would result in the shorter one always winning Penney's Game, since it is contained within the longer one but not at the end. Games like this can be dealt with using a rule for picking sequences such as "one sequence must not be contained within another."

\part{Deriving a formula for win probabilities in games with any number of players}

The last way that we will generalize our formula is to make it work with any number of players.

We will define $n$ to represent the number of players, and we will store the predicted sequences of all players in a list: $\{S_1, S_2, ..., S_n\}$.

The first thing we can do is edit \eqref{NtwoPlayers}. This equation says that in the betting game with two players, they pay each other their winnings. We can make this work with more than two players. A way to do this which keeps the game fair for everyone (this is still necessary), is to say that at the end of the game, each player's winnings are paid by all other players equally. For example, in a game with 5 players, if one player wins \$1, all the others will give that player \$0.25 when the game ends. Mathematically, that rule can be expressed like this:

\begin{equation}\label{Ndef}
	N_{X}(Y) = \frac{1}{n-1} \mathlarger{[}nR_{X}(Y) - \sum_{i=1}^{n}R_{X}(S_i)\mathlarger{]}
\end{equation}

The problem that is now left is that there are $n$ players, so there are not just two win probabilities (previously simply $\mathbb{P}(A)$ and $\mathbb{P}(B) = 1-\mathbb{P}(A)$), but $n$ unknown win probabilities.

However, we can generate enough equations to solve for all of them. For each player, the betting game must be fair. Therefore,

\begin{equation*}
	N_{S_1}(S_\textbf{1}) \cdot \mathbb{P}(S_1) + N_{S_2}(S_\textbf{1}) \cdot \mathbb{P}(S_2) + ... + N_{S_n}(S_\textbf{1}) \cdot \mathbb{P}(S_n) = 0
\end{equation*}

\begin{equation*}
	N_{S_1}(S_\textbf{2}) \cdot \mathbb{P}(S_1) + N_{S_2}(S_\textbf{2}) \cdot \mathbb{P}(S_2) + ... + N_{S_n}(S_\textbf{2}) \cdot \mathbb{P}(S_n) = 0
\end{equation*}

\begin{equation*}
	...(\text{one for the net profit of each player})...
\end{equation*}

\begin{equation*}
	N_{S_1}(S_\textbf{n}) \cdot \mathbb{P}(S_1) + N_{S_2}(S_\textbf{n}) \cdot \mathbb{P}(S_2) + ... + N_{S_n}(S_\textbf{n}) \cdot \mathbb{P}(S_n) = 0
\end{equation*}

And finally, someone must win, so 

\begin{equation*}
	\mathbb{P}(S_1) + \mathbb{P}(S_2) + ... + \mathbb{P}(S_n) = 1
\end{equation*}

Translating this system of linear equations into a matrix equation, we get the general formula to solve for the win probabilities of any number of players:

\begin{equation}\label{generalFormula}
	\begin{bmatrix}
		N_{S_1}(S_1) && N_{S_2}(S_1) && \dots && N_{S_n}(S_1) \\
		N_{S_1}(S_2) && N_{S_2}(S_2) && \dots && N_{S_n}(S_2) \\
		\vdots && \vdots && \ddots && \vdots \\
		N_{S_1}(S_{n-1}) && N_{S_2}(S_{n-1}) && \dots && N_{S_n}(S_{n-1}) \\
		1 && 1 && \dots && 1
	\end{bmatrix}
	\begin{bmatrix}
		\mathbb{P}(S_1) \\ \mathbb{P}(S_2) \\ \vdots \\ \mathbb{P}(S_{n-1}) \\  \mathbb{P}(S_n)
	\end{bmatrix}
	=
	\begin{bmatrix}
		0 \\ 0 \\ \vdots \\ 0 \\ 1
	\end{bmatrix}
\end{equation}

Note that we were able to remove the equation for the last player and replace it by $\mathbb{P}(S_1) + \mathbb{P}(S_2) + ... + \mathbb{P}(S_n) = 1$, since only $n$ equations are necessary.

\part{Two-player games with equal sequence lengths and even flip outcome likelihoods}\label{twoPlayerProofs}

Solving \eqref{Ndef} and \eqref{generalFormula} with $n=2$, we get a formula for the probabilities in a two-player game. This formula is, of course, identical to \eqref{PtwoPlayersFirst}, which was derived earlier on.
\begin{equation}\label{2playerAProb}
	\mathbb{P}(A)=\frac{R_B(B)-R_B(A)}{R_A(A)-R_A(B)+R_B(B)-R_B(A)}
\end{equation}
\begin{equation}\label{2playerBProb}
	\mathbb{P}(B)=\frac{R_A(A)-R_A(B)}{R_B(B)-R_B(A)+R_A(A)-R_A(B)}
\end{equation}
And since either Player A or Player B must win in a game,
\begin{equation*}
	\mathbb{P}(A)+\mathbb{P}(B)=1
\end{equation*}
We will use $s$ to denote the number of possible outcomes of the flip. $s=2$ for coins, $s=6$ for 6-sided dice, etc.

\section{Proving that when sequence S appears, Player S will always win more money than their opponent in the betting game}

In other words, we are making the claim that $R_A(A)>R_A(B)$ in all cases and $R_B(B)>R_B(A)$ in all cases.

We will start by showing that A: 100...0 and B: 000...0 produces the lowest possible $R_A(A)$ and the highest possible $R_A(B)$.
\\\\\\
${R_A(A)}$:
\begin{tabular}{|ccccc|c|}
	\hline
	1 & 0 & 0 & ... & 0 & Gain \\
	\hline
	
	\textcolor{OliveGreen}{1} & \textcolor{OliveGreen}{0} & \textcolor{OliveGreen}{0} & \textcolor{OliveGreen}{...} & \textcolor{OliveGreen}{0} & $s^k$\\
	
	& \textcolor{red}{\sout{1}} & 0 & ... & 0 & $0$ \\
	
	&  & \textcolor{red}{\sout{1}} & ... & 0 & $0$ \\
	
	&  &  & \textcolor{red}{\sout{...}} & 0 & $0$ \\
	
	&  &  &  & \textcolor{red}{\sout{1}} & $0$ \\
	\hline
\end{tabular}
$=s^k$
\\\\
This is the minimum value, since necessarily $A=A$.
\\\\\\
${R_A(B)}$:
\begin{tabular}{|ccccc|c|}
	\hline
	1 & 0 & 0 & ... & 0 & Gain \\
	\hline
	
	\textcolor{red}{\sout{0}} & 0 & 0 & ... & 0 & 0\\
	
	& \textcolor{OliveGreen}{0} & \textcolor{OliveGreen}{0} & \textcolor{OliveGreen}{...} & \textcolor{OliveGreen}{0} & $s^{k-1}$\\
	
	&  & \textcolor{OliveGreen}{0} & \textcolor{OliveGreen}{...} & \textcolor{OliveGreen}{0} & $s^{k-2}$ \\
	
	&  &  & \textcolor{OliveGreen}{...} & \textcolor{OliveGreen}{0} & ... \\
	
	&  &  &  & \textcolor{OliveGreen}{0} & $s$ \\
	\hline
\end{tabular}
$=\mathlarger\sum_{i=1}^{k-1}s^{k-i}$
\\\\
This is the maximum value, since $A \neq B$ or else the game would be invalid.
\\\\
Therefore, if $s^k > \mathlarger\sum_{i=1}^{k-1}s^{k-i}$, ${R_A(A) > R_A(B)}$ will always be true. This is because $R_A(A)$ would be greater than $R_A(B)$ even when it's the most disadvantaged.

$\mathlarger\sum_{i=1}^{k-1}s^{k-i}$ can be rewritten as
$\mathlarger{s^k \sum_{i=1}^{k-1}\left(\frac{1}{s}\right)^i}$, and since it's a sum of positive numbers, it must be less than $\mathlarger{s^k\sum_{i=1}^{\infty}\left(\frac{1}{s}\right)^i}$, a geometric series which is equal to $\mathlarger{s^k\frac{s}{s-1} - s^k}$.

Now, if $s^k \ge s^k\frac{s}{s-1} - s^k$, then $s^k$ will definitely be larger than $\mathlarger{\sum_{i=1}^{k-1}s^{k-1}}$ and our claim will be proven.
\\
\begin{equation*}
	s^k \ge s^k\frac{s}{s-1} - s^k
\end{equation*}
\begin{equation*}
	1 \ge \frac{s}{s-1} - 1
\end{equation*}
\begin{equation*}
	s \ge 2
\end{equation*}
Which is always the case, since there must be at least two possible outcomes from the flip.

This proves that ${R_A(A) > R_A(B)}$. If the exact same process is done after swapping the sequences of A and B, we also learn that $R_B(B)>R_B(A)$.

So the player who has chosen a sequence \underline{will} always get the greatest return when that sequence appears. For example, if Player A's sequence appears in the flips, and the player makes \$10, Player B could not possibly make any more than \$9.

\section{Determining how changes of $R$ values affect $\mathbb{P}(A)$}

It will be useful to know whether increasing each $R$ value will increase or decrease $\mathbb{P}(A)$. Note that because of \eqref{PA+PB=1}, a value that increases $\mathbb{P}(A)$ will necessarily decrease $\mathbb{P}(B)$. We focus on $\mathbb{P}(A)$ and the results for $\mathbb{P}(B)$ will simply be the opposite.

Although all $R$ values depend on each other, artificially increasing each value separately gives a good enough idea of how that value affects $\mathbb{P}(A)$.

We start with $R_B(B)$ and increase its value to $R_B(B) + N$ where $N$ is any natural number greater than 0.

Rewriting \eqref{2playerAProb} with this new value, we get:

\begin{equation*}
	\mathbb{P}_N(A)=\frac{\boldsymbol{(R_B(B)+N)}-R_B(A)}{R_A(A)-R_A(B)+\boldsymbol{(R_B(B)+N)}-R_B(A)}
\end{equation*}

Now, lets check if $\mathbb{P}_N(A) > \mathbb{P}(A)$:

\begin{equation*}
	\mathbb{P}_N(A) > \mathbb{P}(A)
\end{equation*}
\begin{equation*}
	\frac{\mathbb{P}_N(A)}{\mathbb{P}(A)} > 1
\end{equation*}
Dividing, simplifying, and factoring, we get that this is true if and only if:
\begin{equation*}
	\frac{N\left[R_A(A)-R_A(B)\right]}{\left[R_B(B)-R_B(A)\right]\left[R_A(A)-R_A(B)+N+R_B(B)-R_B(A)\right]} > 0
\end{equation*}
We know from the previous section that $R_A(A) > R_A(B)$ and $R_B(B) > R_B(A)$, so the above inequality will always hold true, with all terms being positive numbers.

This means that increasing $R_B(B)$ will always increase $\mathbb{P}(A)$, and decreasing $R_B(B)$ will always decrease $\mathbb{P}(A)$.
\\\\
Next, we will do the same for $R_B(A)$, increasing it to $R_B(A)+N$. This time, we need to note that since $R_B(B)$ must be greater than $R_B(A)$, we have the condition on $N$ that $0 < N < R_B(B)-R_B(A)$.

Rewriting \eqref{2playerAProb}, this time with $R_B(A)$ incremented by $N$, we get:
\begin{equation*}
	\mathbb{P}_N(A) = \frac{R_B(B)-\boldsymbol{(R_B(A)+N)}}{R_A(A)-R_A(B)+R_B(B)-\boldsymbol{(R_B(A)+N)}}
\end{equation*}
Now doing the same process as before, we end up with an increase of $R_B(A)$ increasing $\mathbb{P}(A)$ if and only if:
\begin{equation*}
	\frac{N\left[R_A(B)-R_A(A)\right]}{\left[R_B(B)-R_B(A)\right]\left[R_A(A)-R_A(B)-N+R_B(B)-R_B(A)\right]} > 0
\end{equation*}
We know from the previous section that $R_A(B)-R_A(A)$ must be negative and $R_B(B)-R_B(A)$ must be positive. Additionally, the condition that $N < R_B(B)-R_B(A)$ means that $R_B(B)-R_B(A)-N > 0$.

So in the large inequality, the numerator on the left side will always be negative and the denominator will always be positive, so the inequality will be false and increasing $R_B(A)$ will always decrease $\mathbb{P}(A)$ and vice versa.

We can do the exact same process for B and use the idea that increasing $\mathbb{P}(B)$ will necessarily decrease $\mathbb{P}(A)$ to determine that increasing $R_A(A)$ will always decrease $\mathbb{P}(A)$ and increasing $R_A(B)$ will always increase $\mathbb{P}(A)$, and vice versa.
\\\\
In summary:
\begin{equation}\label{R_A(A)change}
	R_A(A)\uparrow \implies \mathbb{P}(A)\downarrow
\end{equation}
\begin{equation}\label{R_A(B)change}
	R_A(B)\uparrow \implies \mathbb{P}(A)\uparrow
\end{equation}
\begin{equation}\label{R_B(B)change}
	R_B(B)\uparrow \implies \mathbb{P}(A)\uparrow
\end{equation}
\begin{equation}\label{R_B(A)change}
	R_B(A)\uparrow \implies \mathbb{P}(A)\downarrow
\end{equation}
And vice versa.
\\\\

Note that swapping the symbols A and B will give you the results of an equivalent analysis of $\mathbb{P}(B)$.

\section{Proving that the greatest win probability difference occurs when $baa...a$ is played against $aaa...a$ for $b\ne a$}

As a specific example of the case described in the title, let A: 100...0 and B: 000...0 in a game with sequences of length $k$ and with $s$ possible outcomes from the flip.
\\\\
From the previous section, $s^k$ is the minimum possible value of $R_A(A)$, and this maximizes $\mathbb{P}(A)$ by \eqref{R_A(A)change}, and $\mathlarger\sum_{i=1}^{k-1}s^{k-i}$ is the maximum possible value of $R_A(B)$, maximizing $\mathbb{P}(A)$ by \eqref{R_A(B)change}.
\\\\
Determining the other return values:
\\
${R_B(B)}$:
\begin{tabular}{|ccccc|c|}
	\hline
	0 & 0 & 0 & ... & 0 & Gain \\
	\hline
	
	\textcolor{OliveGreen}{0} & \textcolor{OliveGreen}{0} & \textcolor{OliveGreen}{0} & \textcolor{OliveGreen}{...} & \textcolor{OliveGreen}{0} & $s^k$\\
	
	& \textcolor{OliveGreen}{0} & \textcolor{OliveGreen}{0} & \textcolor{OliveGreen}{...} & \textcolor{OliveGreen}{0} & $s^{k-1}$\\
	
	&  & \textcolor{OliveGreen}{0} & \textcolor{OliveGreen}{...} & \textcolor{OliveGreen}{0} & $s^{k-2}$ \\
	
	&  &  & \textcolor{OliveGreen}{...} & \textcolor{OliveGreen}{0} & ... \\
	
	&  &  &  & \textcolor{OliveGreen}{0} & $s$ \\
	\hline
\end{tabular}
$=\mathlarger\sum_{i=0}^{k-1}s^{k-i}$
\\\\
Which is the maximum possible value, maximizing $\mathbb{P}(A)$ by \eqref{R_B(B)change}.
\\\\\\
${R_B(A)}$:
\begin{tabular}{|ccccc|c|}
	\hline
	0 & 0 & 0 & ... & 0 & Gain \\
	\hline
	
	\textcolor{red}{\sout{1}} & 0 & 0 & ... & 0 & $0$\\
	
	& \textcolor{red}{\sout{1}} & 0 & ... & 0 & $0$\\
	
	&  & \textcolor{red}{\sout{1}} & ... & 0 & $0$\\
	
	&  &  & \textcolor{red}{\sout{...}} & 0 & $0$ \\
	
	&  &  &  & \textcolor{red}{\sout{1}} & $0$ \\
	\hline
\end{tabular}
$=0$
\\\\
Which is the minimum possible value, maximizing $\mathbb{P}(A)$ by \eqref{R_B(A)change}.
\\\\
In summary, these two sequences played against each other provide the maximum value of $\mathbb{P}(A)$. This finding will be used in the next section.

\section{Determining the bounds of $\mathbb{P}(A)$ and $\mathbb{P}(B)$}

Substituting the previous section's values which maximize $\mathbb{P}(A)$ into \eqref{2playerAProb}, we get:
\begin{equation*}
	\text{max}\{\mathbb{P}(A)\} = \frac{\mathlarger{\sum_{i=0}^{k-1}s^{k-i}} - 0}{s^k-\mathlarger{\sum_{i=1}^{k-1}s^{k-i}}+\mathlarger{\sum_{i=0}^{k-1}s^{k-i}}-0}
\end{equation*}
\begin{equation*}
	\mathbb{P}(A) \le \frac{1}{2}\sum_{i=0}^{k-1}\frac{1}{s^i}
\end{equation*}
Switching the sequences of A and B, we can also conclude that
\begin{equation*}
	\mathbb{P}(B) \le \frac{1}{2}\sum_{i=0}^{k-1}\frac{1}{s^i}
\end{equation*}
From \eqref{PA+PB=1}, $\mathbb{P}(A) = 1-\mathbb{P}(B)$. So the previous equation implies that:
\begin{equation*}
	\mathbb{P}(A) \ge 1-\frac{1}{2}\sum_{i=0}^{k-1}\frac{1}{s^i}
\end{equation*}
And similarly,
\begin{equation*}
	\mathbb{P}(B) \ge 1-\frac{1}{2}\sum_{i=0}^{k-1}\frac{1}{s^i}
\end{equation*}
Now the bounds for the probability that any sequence $S$ wins can be expressed as:
\begin{equation}\label{PBounds}
	1-\frac{1}{2}\sum_{i=0}^{k-1}\frac{1}{s^i} \le \mathbb{P}(S) \le \frac{1}{2}\sum_{i=0}^{k-1}\frac{1}{s^i}
\end{equation}

\section{Using the probability bounds to study extreme games.}

\subsection{Proving that the game tends to be fair with infinite possible flip outcomes but finite sequence length}

\begin{equation*}
	\lim_{s \rightarrow \infty}\sum_{i=0}^{k-1}\frac{1}{s^i} = \lim_{s \rightarrow \infty} \left[1 + \frac{1}{s} + \frac{1}{s^2} + \dots + \frac{1}{s^{k-1}}\right] = 1
\end{equation*}
Using this insight in \eqref{PBounds},
\begin{equation*}
	1-\frac{1}{2}\cdot1 \le \lim_{s\rightarrow\infty}\mathbb{P}(S) \le \frac{1}{2}\cdot1
\end{equation*}
Therefore $\mathlarger{\lim_{s\rightarrow\infty}}\mathbb{P}(S) = \frac{1}{2}$ by the Squeeze Theorem, and the game tends toward being fair with more possible flip outcomes.

\subsection{Determining the bounds for games with infinitely long sequences but finite possible flip outcomes}
\begin{equation*}
	\lim_{k\rightarrow\infty}\frac{1}{2}\sum_{i=0}^{k-1}\frac{1}{s^i} = \frac{1}{2}\sum_{i=0}^{\infty}\frac{1}{s^i} = \frac{s}{2s-2}
\end{equation*}
Thus taking \eqref{PBounds} as $k\rightarrow\infty$, we get:
\begin{equation}\label{PBoundsKToInfty}
	1-\frac{s}{2s-2} \le \lim_{k\rightarrow\infty} \mathbb{P}(S) \le \frac{s}{2s-2} 
\end{equation}
\begin{equation*}
	\left|\lim_{k\rightarrow\infty}\mathbb{P}(S) - \frac{1}{2}\right| \le \frac{1}{2s-2}
\end{equation*}
So the limit might not exist, but (and this is supported by simulations) the probability of a sequence winning will tend toward being contained within the range $\frac{1}{2s-2}$ greater than or less than 50\% as sequence length approaches infinity.

\subsection{Proving that the game tends to be fair with infinite possible flip outcomes and infinitely long sequences.}
Using \eqref{PBoundsKToInfty} and having $s\rightarrow\infty$,
\begin{equation*}
	\lim_{s\rightarrow\infty}\left[1-\frac{s}{2s-2}\right] \le \lim_{(k, s)\rightarrow(\infty, \infty)} \mathbb{P}(S) \le \lim_{s\rightarrow\infty}\frac{s}{2s-2} 
\end{equation*}
\begin{equation*}
	\frac{1}{2} \le \lim_{(k, s)\rightarrow(\infty, \infty)} \mathbb{P}(S) \le \frac{1}{2}
\end{equation*}
And so by the Squeeze Theorem, $\mathlarger{\lim_{(k, s)\rightarrow(\infty, \infty)} \mathbb{P}(S) = \frac{1}{2}}$

\part{Proving that in two-player games, the player who is predicting a shorter sequence will always have an advantage (except in one specific case)}\label{shorterSequenceProof}

First, we will prove that for all games with A being shorter than B, A: 000...0 and B: 11...100...0 leads to the minimum possible probability for A to win.
\\
${R_A(A)}$:
\begin{tabular}{|ccccc|c|}
	\hline
	0 & 0 & 0 & ... & 0 & Gain \\
	\hline
	
	\textcolor{OliveGreen}{0} & \textcolor{OliveGreen}{0} & \textcolor{OliveGreen}{0} & \textcolor{OliveGreen}{...} & \textcolor{OliveGreen}{0} & $s^{L_A}$\\
	
	& \textcolor{OliveGreen}{0} & \textcolor{OliveGreen}{0} & \textcolor{OliveGreen}{...} & \textcolor{OliveGreen}{0} & $s^{L_A-1}$\\
	
	&  & \textcolor{OliveGreen}{0} & \textcolor{OliveGreen}{...} & \textcolor{OliveGreen}{0} & $s^{L_A-2}$ \\
	
	&  &  & \textcolor{OliveGreen}{...} & \textcolor{OliveGreen}{0} & ... \\
	
	&  &  &  & \textcolor{OliveGreen}{0} & $s$ \\
	\hline
\end{tabular}
$=\mathlarger\sum_{i=0}^{L_A-1}s^{L_A-i}$
\\
Which is the maximum possible value, minimizing $\mathbb{P}(A)$ by \eqref{R_A(A)change} 
\\\\
${R_A(B)}$:
\begin{tabular}{|ccccc|c|}
	\hline
	0 & 0 & 0 & ... & 0 & Gain \\
	\hline
	
	\textcolor{red}{\sout{1}} & 1 & 1 & ... & 0 & $0$\\
	
	& \textcolor{red}{\sout{1}} & 1 & ... & 0 & $0$\\
	
	&  & \textcolor{red}{\sout{1}} & ... & 0 & $0$\\
	
	&  &  & \textcolor{red}{\sout{...}} & 0 & $0$ \\
	
	&  &  &  & \textcolor{red}{\sout{1}} & $0$ \\
	\hline
\end{tabular}
$=0$
\\
Which is the minimum possible value, minimizing $\mathbb{P}(A)$ by \eqref{R_A(B)change}.
\\\\
${R_B(B)}$:
\begin{tabular}{|cccccccc|c|}
	\hline
	1 & 1 & ... & 1 & 0 & 0 & ... & 0 & Gain \\
	\hline
	
	\textcolor{OliveGreen}{1} & \textcolor{OliveGreen}{1} & \textcolor{OliveGreen}{...} & \textcolor{OliveGreen}{1} & \textcolor{OliveGreen}{0} & \textcolor{OliveGreen}{0} & \textcolor{OliveGreen}{...} & \textcolor{OliveGreen}{0} & $s^{L_B}$\\
	
	& \textcolor{OliveGreen}{1} & \textcolor{OliveGreen}{...} & \textcolor{OliveGreen}{1} & \textcolor{red}{\sout{1}} & 0 & ... & 0 & $0$ \\
	
	&  & \textcolor{OliveGreen}{...} & \textcolor{OliveGreen}{1} & \textcolor{red}{\sout{1}} & 1 & ... & 0 & $0$ \\
	
	&  &  & \textcolor{OliveGreen}{1} & \textcolor{red}{\sout{1}} & 1 & ... & 1 & $0$ \\
	
	&  &  &  & \textcolor{red}{\sout{1}} & 1 & ... & 1 & $0$ \\
	
	&  &  &  &  & \textcolor{red}{\sout{1}} & ... & 1 & $0$ \\
	
	&  &  &  &  &  & \textcolor{red}{\sout{...}} & 1 & $0$ \\
	
	&  &  &  &  &  &  & \textcolor{red}{\sout{1}} & $0$ \\
	\hline
\end{tabular}
$=s^{L_B}$
\\
Which is the minimum possible, value since $B=B$. This minimizes $\mathbb{P}(A)$ by \eqref{R_B(B)change}.
\\\\\\
${R_B(A)}$:
\begin{tabular}{|cccccccc|c|}
	\hline
	1 & 1 & ... & 1 & 0 & 0 & ... & 0 & Gain \\
	\hline
	
	& & & \textcolor{red}{\sout{0}} & 0 & 0 & ... & 0 & $0$\\
	
	& & & & \textcolor{OliveGreen}{0} & \textcolor{OliveGreen}{0} & \textcolor{OliveGreen}{...} & \textcolor{OliveGreen}{0} & $s^{L_A-1}$ \\
	
	& & & & & \textcolor{OliveGreen}{0} & \textcolor{OliveGreen}{...} & \textcolor{OliveGreen}{0} & $s^{L_A-2}$ \\
	
	& & & & & & \textcolor{OliveGreen}{...} & \textcolor{OliveGreen}{0} & $...$ \\
	
	&  &  &  &  & &  & \textcolor{OliveGreen}{0} & $s$ \\
	\hline
\end{tabular}
$=\mathlarger{\sum_{i=1}^{L_A-1}s^{L_A-i}}$
\\
Which is the maximum possible value, since A cannot be contained within B or the game will be invalid (in this case, it would result in a constant tie between both sequences, A would make up the end of B). This minimizes $\mathbb{P}(A)$ by \eqref{R_B(A)change}.

Substituting these values which minimize A into \eqref{2playerAProb}, we get

\begin{equation*}
	\text{min}\{\mathbb{P}(A)\} = \frac{s^{L_B} - \mathlarger{\sum_{i=1}^{L_A-1}s^{L_A-i}}}{\mathlarger{\sum_{i=0}^{L_A-1}s^{L_A-i}} - 0 + s^{L_B} - \mathlarger{\sum_{i=1}^{L_A-1}s^{L_A-i}}}
\end{equation*}
\begin{equation}\label{PminDifferentLengths}
	\text{min}\{\mathbb{P}(A)\} = 1 - \frac{s^{L_A}\mathlarger{\sum_{i=0}^{L_A-1}\frac{1}{s^i}}}{s^{L_A} + s^{L_B}}
\end{equation}

To remove the sum, we can say:
\begin{equation*}
	\sum_{i=0}^{L_A-1}\frac{1}{s^i} < \sum_{i=0}^{\infty}\frac{1}{s^i} \text{  with  }\sum_{i=0}^{\infty}\frac{1}{s^i} = \frac{1}{1-\frac{1}{s}}
\end{equation*}

Therefore
\begin{equation*}
	\text{min}\{\mathbb{P}(A)\} > 1 - \frac{s^{L_A}\mathlarger{\frac{1}{1-\frac{1}{s}}}}{s^{L_A} + s^{L_B}}
\end{equation*}
\begin{equation*}
	\text{min}\{\mathbb{P}(A)\} > 1 - \frac{s^{L_A+1}}{(s-1)(s^{L_A}+s^{L_B})}
\end{equation*}

We want to know when A will win no matter which exact sequences are chosen. So we want to know when $\text{min}\{\mathbb{P}(A)\} > \frac{1}{2}$. This will definitely be true when

\begin{equation*}
	1 - \frac{s^{L_A+1}}{(s-1)(s^{L_A}+s^{L_B})} \ge \frac{1}{2}
\end{equation*}

Defining $k$ to be the difference in sequence length $L_B-L_A$, we get that $\text{min}\{\mathbb{P}(A)\} > \frac{1}{2}$ when

\begin{equation*}
	\frac{s^{k+1}-s^k-1}{s} \ge 1
\end{equation*}

For all cases where $s \ge 3$ and $k \ge 1$, we have 

\begin{equation*}
	\frac{s^{k+1}-s^k-1}{s} \ge \frac{3^2-3-1}{3}
\end{equation*}

\begin{equation*}
	\frac{s^{k+1}-s^k-1}{s} \ge \frac{5}{3} \ge 1
\end{equation*}

So with more than two flip outcome possibilities and with any two sequences of different lengths, the shorter one will always have an advantage.

We can find most of the values of $k$ which will give the shorter sequence an advantage when $s=2$ using the same inequality:

\begin{equation*}
	\frac{2^{k+1}-2^k-1}{2} \ge 1
\end{equation*}
\begin{equation*}
	k \ge \log_2(3)
\end{equation*}
\begin{equation*}
	k \ge 2
\end{equation*}
The shorter sequence will always have an advantage when the difference in sequence length is greater than 2, since $k$ must be a natural number.

The only thing left to check is when $s=2$ and $k=1$. We need to find at which $L_A$ Player A always has an advantage. Since $\text{min}\{\mathbb{P}(A)\}$ decreases as $L_A$ increases,
\begin{equation*}
	\text{min}\{\mathbb{P}(A)\}|_{L_A \ge 3} \le \text{min}\{\mathbb{P}(A)\}|_{L_A = 3}
\end{equation*}

To find $\text{min}\{\mathbb{P}(A)\}|_{L_A = 3}$, we need to return to \eqref{PminDifferentLengths}. 

\begin{equation*}
	\text{min}\{\mathbb{P}(A)\}|_{L_A = 3} = 1-\frac{2^3 \mathlarger{\sum_{i=0}^{2} \frac{1}{2^i}}}{2^3+2^4} = \frac{5}{12}
\end{equation*}

Since $\frac{5}{12} < \frac{1}{2}$, $\text{min}\{\mathbb{P}(A)\}|_{L_A \ge 3}$ will always be greater than $\frac{1}{2}$ and Player A will not necessarily have an advantage for all games where $s=2$, $L_A \ge 3$, and $L_B = L_A + 1$.

There are only two possible cases left: when $s=2$, $k=1$, $L_A=1$, and $L_B=2$ and when $s=2$, $k=1$, $L_A=2$, and $L_B=3$. 

The former only has two valid games possible: when A is 0 and B is 11 (or the same but with 0 and 1 swapped). Therefore we can use \eqref{2playerAProb} to determine that $\mathbb{P}(A)=\frac{3}{4}$, so A has the advantage.

The latter is an interesting case, since using \eqref{PminDifferentLengths} gives
\begin{equation*}
	\text{min}\{\mathbb{P}(A)\} = \frac{1}{2}
\end{equation*}

So A always has an advantage except in one game: when A chooses 00 and B chooses 110 (or A chooses 11 and B chooses 001), in which case the game is fair.

\part {Software}

This paper comes with two bits of software: a simulator which can find experimental win probability values with extremely high precision and a calculator which we used to help guide where research should be done. Both can be found at \href{https://will-drac.github.io/Penneys-Game/}{will-drac.github.io/Penneys-Game/}.

\section{Verifying the formula with simulations}

We are confident that all our results are correct, because they match with billions of data points found by our virtual Penney's Game simulator, which can be found on the website above. The simulator runs on the browser and runs computations on the device's GPU using WebGPU. The simulator works with all of the variations discussed in this paper.

Each thread plays a game until one player has won and writes down the winner in a local bin in GPU memory. The results from all of these bins then get summed using multiple passes of a parallel reduction algorithm which is also run on the GPU, until there is just one bin containing the total number of wins from each player. This vector of $<\text{Player 1 wins}, \text{Player 2 wins}, ..., \text{Player $n$ wins}>$ then gets passed to the CPU and divided by the total number of games played to obtain the experimental win probability for each player.

It uses a pseudorandom number generator which is adapted from the hybrid LCG and Tausworthe generator described in Nvidia's GPU Gems 3 \parencite{prng}.

\section {Creating a tool to aid in research of Penney's Game}

The proofs done in Parts \ref{twoPlayerProofs} and \ref{shorterSequenceProof} were scouted for with the help of a software tool we created to visualize patterns and trends in Penney's Game.

(strategies stuff here)

\part {Physically modelling unfair coin flips and dice rolls \label{physicalModelling}}

Our equations can take into account random outcome generators with any probability distribution because of the $\mathbb{P}(Y_j)$ term in \eqref{Rdef}. We could like to physically ground this by modelling the probability distribution of loaded dice and unfairly flipped coins.

\section{Deriving an approximate probability distribution for loaded dice}

Our goal in this section is to find a formula for the probability that a loaded die (a die with it's centre of mass offset) lands on each of its faces. We will be making many key assumptions which are not true, but may be close enough.

\begin{enumerate}
	\item There is some point in the rolling of a die at which it is touching the table at one edge, without any rotational or translational motion. Imagine a die teetering on one edge, about to fall over so that it lands on a face but it hasn't started moving yet. This is pictured in Figure \ref{fig:loadeddie}.
	\item It is equally likely that a die lands on all edges.
	\item It is equally likely for a die to come at rest like this at any angle $\theta$ (as defined in Figure \ref{fig:loadeddie}).
\end{enumerate}

\begin{figure}[H]
	\centering
	\includegraphics[width=0.5\linewidth]{loadedDie}
	\caption[A loaded die teetering on one of its edges]{A side view of a loaded die teetering on one of its edges. We are assuming that the die is currently at rest. Therefore, it will fall to whichever side the centre of mass (C.O.M) is on. In this case, it will rotate clockwise until it lands on the lower face.}
	\label{fig:loadeddie}
\end{figure}

Let's take the centre of mass to be at the tip of the vector $<x, z>$. After a rotation by $\theta$, it's new position $<x', z'>$ will be:

\begin{equation*}
	\begin{bmatrix} x' \\ z' \end{bmatrix} = \begin{bmatrix} \cos\theta & -\sin\theta \\ \sin\theta & \cos\theta \end{bmatrix} \begin{bmatrix} x \\ z \end{bmatrix}
\end{equation*}


Because of our assumptions, the probability that the die lands back on the face where $\theta=0$ will be 

\begin{equation*}
	\mathbb{P} = \frac{\text{angles where the C.O.M will make it rotate clockwise}}{\text{total angles possible}}
\end{equation*}

\begin{equation*}
	 \mathbb{P} = \frac{\text{angles where $x' > 0$}}{\pi/2}
\end{equation*}

We can find which angles will make $x' > 0$:

\begin{equation*}
	x' > 0
\end{equation*}
\begin{equation*}
	x\cos\theta - z\sin\theta > 0
\end{equation*}
\begin{equation*}
	\frac{x}{z} > \tan\theta
\end{equation*}

So it will fall back to $\theta=0$ for all $\theta < \arctan\mathlarger{\frac{x}{z}}$.

\begin{equation}\label{dieEdgeProb}
	\mathbb{P} = \frac{\arctan(x/z)}{\pi/2} = \frac{2}{\pi} \arctan\left(\frac{x}{z}\right)
\end{equation}

However, if we really want to find the probability of it landing on that face, we have to take into account that there are four edges which could possibly lead the die to fall onto that face. We can derive a formula which takes into account all four.

Let's imagine a die of side length $s$ and $r=\frac{s}{2}$. We will place the die on the xy-plane such that it is centred at $(0, 0, r)$. This is pictured in Figure \ref{fig:loadeddie3d}.

\begin{figure}[H]
	\centering
	\includegraphics[width=0.7\linewidth]{loadedDie3d}
	\caption{Setup for calculating the probability of a loaded dice landing on the down-facing side. The green arrows represent the rotation and translation which are used to line up the selected edge with the y-axis.}
	\label{fig:loadeddie3d}
\end{figure}

For each edge of the face which is currently pointing in the $-z$ direction, we will:

\begin{enumerate}
	\item Rotate the die so that the edge is centred on $(-r, 0, 0)$ and parallel to the y-axis. This edge will be the one which will use \eqref{dieEdgeProb} on.
	\item Translate the die forward in the x-direction so that the edge is centred at the origin. We now have the situation in Figure \ref{fig:probGraph} for our selected face but with $\theta=0$ because we haven't started checking the angles yet.
	\item Determine the probability that it lands on the face which is facing in the $-z$ direction when $\theta=0$ using \eqref{dieEdgeProb}.
	\item Mix the probabilities from each edge to get the final probability for the face.
\end{enumerate}

From steps one and two, we must rotate the centre of mass $<x, y, z>$ and then translate it to follow the die being rotated and translated:

\begin{equation*}
	\begin{bmatrix}x'\\y'\\z'\end{bmatrix} = \begin{bmatrix}\cos\psi & -\sin\psi & 0 \\ \sin\psi & \cos\psi & 0 \\ 0 & 0 & 1\end{bmatrix} \begin{bmatrix}x\\y\\z\end{bmatrix} + \begin{bmatrix}r\\0\\0\end{bmatrix}
\end{equation*}

If the die starts as it is in Figure \ref{fig:loadeddie3d}, we have one edge with no rotation ($\psi=0$) and three edges each $\frac{\pi}{2} \text{rad}$ away from each other. To do this, we let $\psi = n\pi/2 \text{ with } n=\{0, 1, 2, 3\}$. Additionally, we are assuming that there is equal likelihood that the die lands on each of the 12 edges, so the chance that it lands on any one of the faces is $\frac{1}{2}$ So the probability coming from one of the edges that the die lands on the bottom face is:

\begin{equation*}
	\mathbb{P}_n = \frac{1}{12} \cdot \frac{2}{\pi} \arctan\left(\frac{x\cos(n\frac{\pi}{2})-y\sin(n\frac{\pi}{2})+r}{z}\right)
\end{equation*}
since
\begin{equation*}
	\arctan\left(\frac{x'}{z'}\right) = \arctan\left(\frac{x\cos\psi-y\sin\psi+r}{z}\right)
\end{equation*}
after the centre of mass rotates by $\psi$.

Finally, the total probability of the die landing on the face is the sum of the contributions by each edge of the face:

\begin{equation*}
	\mathbb{P} = \frac{1}{6\pi} \sum_{n=0}^{3} \arctan\left(\frac{x\cos(n\frac{\pi}{2})-y\sin(n\frac{\pi}{2})+r}{z}\right)
\end{equation*}

One last thing must be done, since we want a single formula which returns the probability for all sides of a die. To do this, we need a procedure to align the die as it is in Figure \ref{fig:loadeddie3d} for all faces.

widjawoidjwoiaj big long thing

\section{Simulating an unfair coin flip}

\textcite{unfairCoin} describe a way to flip a coin which makes it more likely to land on a particular side. Put simply, if a coin is spun like a flying disc, the side which started facing upwards will stay that way. In Theorem 2, Diaconis \textit{et al.} provide a formula for the probability that the coin lands on the upward-facing side as a function of the angle between the normal direction of the coin and its axis of rotation $\psi$:

\begin{equation}\label{coinProbByAngle}
	p = \begin{cases}
		\frac{1}{2} + \frac{1}{\pi}\arcsin(\cot^2(\psi)) & \text{ if } \frac{\pi}{4}<\psi<\frac{3\pi}{4}
		\\
		1 & \text{ if } 0<\psi<\frac{\pi}{4} \text{ or } \frac{\pi}{4} < \psi < \pi
	\end{cases}
\end{equation}

This is what would give us our value for $\mathbb{P}(Y_j)$. To add on to their work, we created a flipping coin simulator which demonstrates the phenomenon they describe. The simulator can be found at \href{https://will-drac.github.io/Penneys-Game/flipping%20coin/}{will-drac.github.io/Penneys-Game/flipping\%20coin/}

\begin{figure}[H]
	\centering
	\includegraphics[width=0.5\linewidth]{flippingCoin}
	\caption{Freeze frame of the simulator, showing the coin's normal in yellow and the axis of rotation in cyan. As described by Diaconis \textit{et al.}, the normal rotates around the axis.}
	\label{fig:flippingcoin}
\end{figure}

\subsection{Finding the force on the coin as a function of the coin's probability}

Another addition to \textcite{unfairCoin}'s work is a derivation of the force vector required to give the coin a particular probability.

Inverting \eqref{coinProbByAngle}, we get the angle between the coin's normal direction and its rotational axis $\psi$ as a function of the probability it produces $p$:

\begin{equation}\label{coinAngleByProb}
	\psi(p) = \arctan\left(\left[\sin(\pi p-\frac{\pi}{2})\right]^{-\frac{1}{2}}\right) \text{ for } p \in \left[\frac{1}{2}, 1\right]
\end{equation}

We imagine a coin receiving a force which is anywhere except at the coin's centre (because that would result in no rotation), and the force having a large enough magnitude that the coin will make enough flips in the air so that the outcome is really random. We define a coordinate system as seen in Figure \ref{fig:coincoords}. The normal of the coin is made to be $<0, 0, 1>$.

\begin{figure}[H]
	\centering
	\includegraphics[width=0.7\linewidth]{coinCoords}
	\caption{Coordinate system set up to determine the force vector $F$ required to give the coin a particular probability $p$. The origin is placed at the center of the coin and the force lies on the x-axis.}
	\label{fig:coincoords}
\end{figure}

When the force $\vec{F}=<F_x, F_y, F_z>$ is applied to the coin, there will be a torque which rotates the coin about its centre of mass and in the direction of the torque $\vec{\tau}$. So the axis of rotation is parallel to the torque.

Calling the normal of the coin $\hat{n}$, $\psi$ can be defined in this way:

\begin{equation*}
	\hat{n} \cdot \vec{\tau} = |\hat{n}| |\vec{\tau}| \cos\psi \implies \psi = \arccos\left(\frac{\hat{n}\cdot\vec{\tau}}{|\vec{\tau}|}\right)
\end{equation*}

We can calculate $\vec{\tau}$ as a function of $\vec{F}$

\begin{equation*}
	\vec{\tau} = \vec{r}\times\vec{F} = \begin{bmatrix}r\\0\\0\end{bmatrix} \times \begin{bmatrix}F_x \\ F_y \\ F_z\end{bmatrix} = \begin{bmatrix}0\\-r F_z\\r F_y\end{bmatrix}
\end{equation*}

and find that

\begin{equation*}
	\psi = \arccos \left(\begin{bmatrix}0\\0\\1\end{bmatrix} \cdot \begin{bmatrix}0\\-r F_z\\r F_y\\\end{bmatrix} \cdot \frac{1}{r\sqrt{F_y^2+F_z^2}} \right) = \arccos \left(\frac{F_y}{\sqrt{F_y^2+F_z^2}}\right) = \arctan\frac{F_z}{F_y}
\end{equation*}

A general form of a definition for $\vec{F}$ which satisfies $\psi = \arctan\frac{F_z}{F_y}$ is

\begin{equation*}
	\vec{F}(p) = \begin{bmatrix}a\\b\cos\left(\psi(p)\right)\\b\sin\left(\psi(p)\right)\end{bmatrix}
\end{equation*}

With $a$ being any real number and $b$ being any non-zero real number. Substituting $\psi$ with \eqref{coinAngleByProb}, we get $\vec{F}$ as a function of $p$.

\part {Conclusion}

We successfully extended the analogy of the betting game and created a formula for probability of each player winning in many variations of Penney's Game: games with any number of players, players predicting any number of flips even if they are different to each other, any kind of random outcome generator, and any probability distribution on the random outcome generator. We then physically modelled what it means to have a skewed probability distribution on dice and coins. We were also able to create a simulator which is able to verify our results beyond doubt. Finally, we developed a software tool which helped us to determine other trends and patterns in the game: the game limits to being fair as the number of possible outcomes of the flip tends to infinity but not as length of sequence tends to infinity in two-player games, and the shorter sequence almost always has an advantage, except in a few known cases.

\part {References}
\printbibliography[heading=none]



\end{document}